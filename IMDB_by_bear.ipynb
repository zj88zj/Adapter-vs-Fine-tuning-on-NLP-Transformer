{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f5b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adapter-transformers in c:\\users\\junfe\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (2021.8.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (0.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (0.0.46)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (1.20.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from adapter-transformers) (0.10.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->adapter-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from packaging>=20.0->adapter-transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from tqdm>=4.27->adapter-transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests->adapter-transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests->adapter-transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests->adapter-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests->adapter-transformers) (3.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from sacremoses->adapter-transformers) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from sacremoses->adapter-transformers) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from sacremoses->adapter-transformers) (7.1.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\junfe\\anaconda3\\lib\\site-packages (1.16.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (2021.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (0.2.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: dill in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\junfe\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U adapter-transformers\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7f1d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\Junfe\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb10f27c68344d1b0ff6e2b9fb9a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': 25000, 'test': 25000, 'unsupervised': 50000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddeefec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\Junfe\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-21f5fdd3723ee985.arrow and C:\\Users\\Junfe\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-5ac3cbe7f17fba34.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 20000, 'test': 25000, 'validation': 5000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, valid_dataset= dataset[\"train\"].train_test_split(test_size=0.2).values()\n",
    "dataset = DatasetDict({\"train\":train_dataset,\"test\":dataset[\"test\"], \"validation\":valid_dataset})\n",
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb0f7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'All the elements for a bad night at the movies are in place: dialog riddled with biological techno-babble, chintzy sets, balsa-wood acting, a horrific late-\\'80s Casio score, and an overall look that suggests anything on the Sci-Fi Channel\\'s programming schedule, circa 1993. Though \"Metamorphosis\" starts off with a lot of promise, the film unravels into bland idiocy and MST3K-style cheese as Clark Kent wannabe \\'Doctor\\' Peter Houseman (Gene LeBrock) is pressured into releasing information on his secretive projects. But when he tests his vague experiment on himself, he transforms into a vaguely-defined creature (that bears more than a passing resemblance to \\'Dr. Freudstein\\' from \"House by the Cemetery\"). The FX work is fairly good for such an obviously low-budget production (though I suspect most of it is kept in shadow for a reason), but overall, \"Metamorphosis\" leaves a bad retro aftertaste in your guts, in spite of its hopes to sway us otherwise. I can\\'t help but agree with one character\\'s closing remark: \"(It was) A nightmare...from the past!\"',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb6b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_l = max([len(d['text']) for d in dataset[\"train\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9568337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Junfe\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-5f446d4bfb444ffb.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Junfe\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-36a0f29abbc0128a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Junfe\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-fd1075f44aed36a3.arrow\n",
      "C:\\Users\\Junfe\\AppData\\Local\\Temp/ipykernel_44680/1657904570.py:12: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use DatasetDict.rename_column instead.\n",
      "  dataset.rename_column_(\"label\", \"labels\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Encode the input data\n",
    "dataset = dataset.map(encode_batch, batched=True)\n",
    "# The transformers model expects the target class column to be named \"labels\"\n",
    "dataset.rename_column_(\"label\", \"labels\")\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d609bc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModelWithHeads\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=2,\n",
    ")\n",
    "model = RobertaModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45eea6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new adapter\n",
    "model.add_adapter(\"imdb\")\n",
    "# Add a matching classification head\n",
    "model.add_classification_head(\n",
    "    \"imdb\",\n",
    "    num_labels=2,\n",
    "    id2label={ 0: \"ðŸ‘Ž\", 1: \"ðŸ‘\"}\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "# Activate the adapter\n",
    "model.train_adapter(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c53831c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import TrainingArguments, AdapterTrainer, EvalPrediction\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=200,\n",
    "    output_dir=\"./training_output\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_accuracy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0e810",
   "metadata": {},
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42dcefa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 20000\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 35:08, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.263700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.224400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.205200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.196200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.176700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.181600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.138700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.155400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.079600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.095200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.099100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./training_output\\checkpoint-500\n",
      "Configuration saved in ./training_output\\checkpoint-500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-1000\n",
      "Configuration saved in ./training_output\\checkpoint-1000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-1000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-1000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-1000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-1500\n",
      "Configuration saved in ./training_output\\checkpoint-1500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-1500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-1500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-1500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-1500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-2000\n",
      "Configuration saved in ./training_output\\checkpoint-2000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-2000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-2000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-2000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-2500\n",
      "Configuration saved in ./training_output\\checkpoint-2500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-2500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-2500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-2500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-2500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-3000\n",
      "Configuration saved in ./training_output\\checkpoint-3000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-3000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-3000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-3000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-3500\n",
      "Configuration saved in ./training_output\\checkpoint-3500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-3500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-3500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-3500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-3500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-4000\n",
      "Configuration saved in ./training_output\\checkpoint-4000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-4000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-4000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-4000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-4500\n",
      "Configuration saved in ./training_output\\checkpoint-4500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-4500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-4500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-4500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-4500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-5000\n",
      "Configuration saved in ./training_output\\checkpoint-5000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-5000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-5000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-5000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-5500\n",
      "Configuration saved in ./training_output\\checkpoint-5500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-5500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-5500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-5500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-5500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-6000\n",
      "Configuration saved in ./training_output\\checkpoint-6000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-6000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-6000\\imdb\\head_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output\\checkpoint-6000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-6000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-6000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-6000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-6000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-6500\n",
      "Configuration saved in ./training_output\\checkpoint-6500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-6500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-6500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-6500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-6500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-6500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-6500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-6500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-7000\n",
      "Configuration saved in ./training_output\\checkpoint-7000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-7000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-7000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-7000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-7500\n",
      "Configuration saved in ./training_output\\checkpoint-7500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-7500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-7500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-7500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-7500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-8000\n",
      "Configuration saved in ./training_output\\checkpoint-8000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-8000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-8000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-8000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-8500\n",
      "Configuration saved in ./training_output\\checkpoint-8500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-8500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-8500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-8500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-8500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-9000\n",
      "Configuration saved in ./training_output\\checkpoint-9000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-9000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-9000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-9000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-9500\n",
      "Configuration saved in ./training_output\\checkpoint-9500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-9500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-9500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-9500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-9500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-10000\n",
      "Configuration saved in ./training_output\\checkpoint-10000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-10000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-10000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-10000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-10500\n",
      "Configuration saved in ./training_output\\checkpoint-10500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-10500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-10500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-10500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-10500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-11000\n",
      "Configuration saved in ./training_output\\checkpoint-11000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-11000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-11000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-11000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-11500\n",
      "Configuration saved in ./training_output\\checkpoint-11500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-11500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-11500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11500\\imdb\\pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./training_output\\checkpoint-11500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-11500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-12000\n",
      "Configuration saved in ./training_output\\checkpoint-12000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-12000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-12000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-12000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-12500\n",
      "Configuration saved in ./training_output\\checkpoint-12500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-12500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-12500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-12500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-12500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-13000\n",
      "Configuration saved in ./training_output\\checkpoint-13000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-13000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-13000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-13000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-13500\n",
      "Configuration saved in ./training_output\\checkpoint-13500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-13500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-13500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-13500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-13500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-14000\n",
      "Configuration saved in ./training_output\\checkpoint-14000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-14000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-14000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-14000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14000\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-14500\n",
      "Configuration saved in ./training_output\\checkpoint-14500\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14500\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-14500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-14500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14500\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-14500\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-14500\\imdb\\pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output\\checkpoint-15000\n",
      "Configuration saved in ./training_output\\checkpoint-15000\\imdb\\adapter_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-15000\\imdb\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output\\checkpoint-15000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-15000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-15000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-15000\\imdb\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output\\checkpoint-15000\\imdb\\head_config.json\n",
      "Module weights saved in ./training_output\\checkpoint-15000\\imdb\\pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15000, training_loss=0.1554879654566447, metrics={'train_runtime': 2108.956, 'train_samples_per_second': 56.9, 'train_steps_per_second': 7.113, 'total_flos': 3.212080128e+16, 'train_loss': 0.1554879654566447, 'epoch': 6.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e39f89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2421850562095642,\n",
       " 'eval_acc': 0.944,\n",
       " 'eval_runtime': 39.2779,\n",
       " 'eval_samples_per_second': 127.298,\n",
       " 'eval_steps_per_second': 15.912,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c20c1128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ðŸ‘', 'score': 0.9924499988555908}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=training_args.device.index)\n",
    "\n",
    "classifier(\"This is awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20a7c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./final_adapter\\adapter_config.json\n",
      "Module weights saved in ./final_adapter\\pytorch_adapter.bin\n",
      "Configuration saved in ./final_adapter\\head_config.json\n",
      "Module weights saved in ./final_adapter\\pytorch_model_head.bin\n",
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "model.save_adapter(\"./final_adapter\", \"imdb\")\n",
    "\n",
    "!ls -lh final_adapter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
